[INFO] (utils) Arguments:
[INFO] (utils)   batch_size: 4
[INFO] (utils)   command: .\DNN\train.py -d .\data\SemEval_task5\df_train.csv --trial .\data\SemEval_task5\df_test.csv -s .\data\sentiment_datasets\train_E6oV3lV.csv --word_list .\data\word_list\word_all.txt --emb .\data\glove.6B.300d.txt -o .\output_dir -b 4 --epochs 1 --lr 0.002 --maxlen 50 -t HHMM_transformer
[INFO] (utils)   data_path: .\data\SemEval_task5\df_train.csv
[INFO] (utils)   dropout_prob: 0.1
[INFO] (utils)   emb_dim: 300
[INFO] (utils)   emb_path: .\data\glove.6B.300d.txt
[INFO] (utils)   epochs: 1
[INFO] (utils)   humor_data_path: None
[INFO] (utils)   learn_rate: 0.002
[INFO] (utils)   loss: ce
[INFO] (utils)   maxlen: 50
[INFO] (utils)   model_type: HHMM_transformer
[INFO] (utils)   non_gate: None
[INFO] (utils)   out_dir_path: .\output_dir
[INFO] (utils)   sarcasm_data_path: None
[INFO] (utils)   sentiment_data_path: .\data\sentiment_datasets\train_E6oV3lV.csv
[INFO] (utils)   trial_data_path: .\data\SemEval_task5\df_test.csv
[INFO] (utils)   vocab_path: None
[INFO] (utils)   word_list_path: .\data\word_list\word_all.txt
[INFO] (utils)   word_norm: 1
[INFO] (data_reader) Creating vocabulary.........
[INFO] (data_reader)   407157 total words, 37258 unique words
[INFO] (data_reader)   Vocab size: 37258
[INFO] (data_reader) <unk> hit rate: 0.00%
[INFO] (data_reader) <unk> hit rate: 0.01%
